---
description: WebSocket protocol specifications and message formats for real-time audio streaming
globs: "**/*websocket*.{ts,py}", "**/api/**/*.{ts,py}", "**/ws/**/*.{ts,py}"
alwaysApply: true
---
# API Protocol & Message Formats

## WebSocket Protocol Overview

### Connection Flow
```
1. Client ‚Üí ws://localhost:8000/ws/speech
2. Server ‚Üí Accept connection, create session
3. Client ‚Üí Send audio chunks (binary)
4. Server ‚Üí Send recognition results (JSON)
5. Client ‚Üí Send control messages (JSON)
6. Server ‚Üí Send status updates (JSON)
```

## Message Types

### Client ‚Üí Server Messages

#### Audio Data (Binary)
```typescript
// Raw audio blob from MediaRecorder
ws.send(audioBlob); // Blob type: audio/webm;codecs=opus
```

#### Control Messages (JSON)
```typescript
// Stop recording
{
  "type": "STOP_RECORDING",
  "reason": "User stopped voice recognition"
}

// Keep-alive
{
  "type": "KEEP_ALIVE",
  "session_id": "uuid-string"
}
```

### Server ‚Üí Client Messages

#### Recognition Results
```json
{
  "transcript": "Hello, can you hear me?",
  "confidence": 0.95,
  "is_final": true,
  "ai_response": "Hello! I can help you with Gmail.",
  "processing": false,
  "status": "Processing your request...",
  "session_id": "uuid-string",
  "timestamp": "2024-01-01T12:00:00.000Z"
}
```

#### Status Updates
```json
// Ready for next command
{
  "type": "ready_for_next",
  "status": "Ready for your next command",
  "session_id": "uuid-string",
  "timestamp": "2024-01-01T12:00:00.000Z"
}

// Keep-alive acknowledgment
{
  "type": "keep_alive_ack",
  "session_id": "uuid-string",
  "timestamp": "2024-01-01T12:00:00.000Z"
}

// Error message
{
  "error": "Audio Timeout Error",
  "session_id": "uuid-string"
}
```

## Session States

### Server Session States
```python
# ConversationState.status values
'idle'              # Initial state
'listening'         # Receiving audio
'processing_stt'    # Speech-to-text processing
'awaiting_ai'       # Waiting for LLM response
'ai_responding'     # Sending AI response
'ready_for_input'   # Ready for next command
```

### Client State Flags
```typescript
isRecording          // MediaRecorder active
isProcessingCommand  // AI processing command
shouldSendAudio      // Control audio transmission
isWebSocketConnected // WebSocket connection status
isContinuousMode     // Continuous conversation mode
```

## Audio Format Specifications

### MediaRecorder Configuration
```typescript
{
  mimeType: 'audio/webm;codecs=opus',
  audioBitsPerSecond: 16000  // 16kHz
}
```

### Google Speech API Configuration
```python
{
  "encoding": "WEBM_OPUS",
  "sample_rate_hertz": 16000,
  "language_code": "en-US",
  "enable_automatic_punctuation": True,
  "model": "latest_short",
  "use_enhanced": True
}
```

## Error Handling Protocol

### Connection Errors
```typescript
// Client-side reconnection
if (ws.readyState !== WebSocket.OPEN) {
  if (reconnectAttempts < MAX_RECONNECT_ATTEMPTS) {
    setTimeout(() => setupWebSocket(), 
      Math.min(1000 * reconnectAttempts, 5000));
  }
}
```

### Audio Timeout Prevention
```typescript
// Client: Stop sending audio during processing
if (isProcessingCommand) {
  shouldSendAudio = false;
}

// Server: Handle long silence
if (no_audio_for_5_minutes) {
  send_ping_message();
}
```

## Chrome Extension Message Protocol

### Message Types
```typescript
// Extension internal messages
interface ExtensionMessage {
  type: 
    | 'TOGGLE_EXTENSION'
    | 'START_VOICE_RECOGNITION'
    | 'STOP_VOICE_RECOGNITION'
    | 'VOICE_COMMAND'
    | 'VOICE_RECOGNITION_STARTED'
    | 'VOICE_RECOGNITION_RESULT'
    | 'VOICE_RECOGNITION_ERROR'
    | 'VOICE_RECOGNITION_ENDED'
    | 'READY_FOR_NEXT_COMMAND';
  // Additional fields based on type
  transcript?: string;
  confidence?: number;
  ai_response?: string;
  error?: string;
  status?: string;
  timestamp?: string;
}
```

### Message Flow Examples
```
User speaks ‚Üí Content Script ‚Üí Background ‚Üí Content Script ‚Üí WebSocket
WebSocket response ‚Üí Content Script ‚Üí Background ‚Üí Popup UI
```

## REST API Endpoints

### Health Check
```
GET /api/health
Response: {
  "status": "healthy",
  "speech_to_text_available": true
}
```

### Speech Status
```
GET /api/speech/status
Response: {
  "available": true,
  "service": "Google Cloud Speech-to-Text"
}
```

## Security Considerations

### CORS Headers
```python
allow_origins = [
  "chrome-extension://[EXTENSION_ID]",
  "https://mail.google.com"
]
```

### Authentication
- Google Cloud: Service account JSON
- Gemini API: API key in environment
- No auth required for WebSocket (local only)

## Performance Guidelines

### Audio Streaming
- Chunk size: 250ms (optimal for real-time)
- Sample rate: 16kHz (speech optimized)
- Format: WEBM_OPUS (compressed)

### Message Frequency
- Interim results: As received
- Keep-alive: Every 5 minutes during idle
- Status updates: On state changes only

### Resource Management
- Max concurrent sessions: Limited by server
- Session timeout: On WebSocket disconnect
- Browser session reuse: Per conversation session

## Debugging Protocol

### Client-side Logging
```typescript
console.log('üé§ Voice activity detected');
console.log('üì§ Sending audio chunk:', size);
console.log('üîå WebSocket connected');
console.log('‚úÖ Final result:', transcript);
console.log('‚ùå Error:', error);
```

### Server-side Logging
```python
logger.info(f"[Session {id}] State: {status}")
logger.debug(f"üì• Audio chunk: {size} bytes")
logger.error(f"‚ùå Speech API error: {error}")
```

## Extension Manifest Permissions

### Required Permissions
```json
{
  "permissions": [
    "activeTab",      // Access current tab
    "storage"         // Store extension state
  ],
  "host_permissions": [
    "https://mail.google.com/*"  // Gmail access
  ],
  "content_scripts": [{
    "matches": ["https://mail.google.com/*"],
    "js": ["email-handler.js"]
  }]
}
```
